[
    {
        "instance_id": "sf_bq036",
        "db_id": "GITHUB_REPOS",
        "question": "What was the average number of GitHub commits made per month in 2016 for repositories containing Python code?",
        "db_type": "snowflake",
        "db_size": 34,
        "query": "",
        "external_path": "",
        "error_info": "Error occurred while executing act() on sample 0: Unable to load valid database schema for sample 0."
    },
    {
        "instance_id": "sf_bq100",
        "db_id": "GITHUB_REPOS",
        "question": "How can we identify the top 10 most frequently used packages in GitHub repository contents by looking for import statements enclosed in parentheses, splitting any multi-line imports by newlines, extracting package names that appear within double quotes, counting how often these packages appear, ignoring any null results, and finally ordering them in descending order of their frequency? The final answer should remove the quotation marks.",
        "db_type": "snowflake",
        "db_size": 34,
        "query": "",
        "external_path": "",
        "error_info": "Error occurred while executing act() on sample 1: Unable to load valid database schema for sample 1."
    },
    {
        "instance_id": "sf_bq101",
        "db_id": "GITHUB_REPOS",
        "question": "From GitHub Repos contents, how can we identify the top 10 most frequently imported package names in Java source files by splitting each file's content into lines, filtering for valid import statements, extracting only the package portion using a suitable regex, grouping by these extracted package names, counting their occurrences, and finally returning the 10 packages that appear most often in descending order of frequency?",
        "db_type": "snowflake",
        "db_size": 34,
        "query": "",
        "external_path": "",
        "error_info": "Error occurred while executing act() on sample 2: Unable to load valid database schema for sample 2."
    },
    {
        "instance_id": "sf_bq225",
        "db_id": "GITHUB_REPOS",
        "question": "From the GitHub repository files in 'github_repos.sample_files' joined with 'github_repos.sample_contents', which 10 programming languages occur most frequently (based on recognized file extensions) in files that have non-empty content, ordered by their file counts in descending order?",
        "db_type": "snowflake",
        "db_size": 34,
        "query": "",
        "external_path": "..\\benchmarks\\spider2\\lite\\external\\lang_and_ext.md",
        "error_info": "Error occurred while executing act() on sample 3: Unable to load valid database schema for sample 3."
    },
    {
        "instance_id": "sf_bq180",
        "db_id": "GITHUB_REPOS",
        "question": "Get the top 5 most frequently used module names from Python (`.py`) and R (`.r`) scripts, counting occurrences of modules in `import` and `from` statements for Python, and `library()` calls for R. The query should consider only Python and R files, group by module name, and return the top 5 modules ordered by frequency.",
        "db_type": "snowflake",
        "db_size": 34,
        "query": "",
        "external_path": "",
        "error_info": "Error occurred while executing act() on sample 4: Unable to load valid database schema for sample 4."
    },
    {
        "instance_id": "sf_bq233",
        "db_id": "GITHUB_REPOS",
        "question": "Can you analyze the joined data from github repos files and github_repos contents, focusing only on files ending with '.py' or '.r', then extract Python modules from 'import' or 'from ... import' lines and R libraries from 'library(...)' lines, count their occurrences, and finally list the results sorted by language and by the number of occurrences in descending order?",
        "db_type": "snowflake",
        "db_size": 34,
        "query": "WITH extracted_modules AS (\nSELECT \n    el.\"file_id\" AS \"file_id\", \n    el.\"repo_name\", \n    el.\"path\" AS \"path_\", \n    REPLACE(line.value, '\"', '') AS \"line_\",\n    CASE\n        WHEN ENDSWITH(el.\"path\", '.py') THEN 'python'\n        WHEN ENDSWITH(el.\"path\", '.r') THEN 'r'\n        ELSE NULL\n    END AS \"language\",\n    CASE\n        WHEN ENDSWITH(el.\"path\", '.py') THEN\n            ARRAY_CAT(\n                ARRAY_CONSTRUCT(REGEXP_SUBSTR(line.value, '\\\\bimport\\\\s+(\\\\w+)', 1, 1, 'e')),\n                ARRAY_CONSTRUCT(REGEXP_SUBSTR(line.value, '\\\\bfrom\\\\s+(\\\\w+)', 1, 1, 'e'))\n            )\n        WHEN ENDSWITH(el.\"path\", '.r') THEN\n            ARRAY_CONSTRUCT(REGEXP_SUBSTR(line.value, 'library\\\\s*\\\\(\\\\s*([^\\\\s)]+)\\\\s*\\\\)', 1, 1, 'e'))\n        ELSE ARRAY_CONSTRUCT()\n    END AS \"modules\"\nFROM (\n    SELECT\n        ct.\"id\" AS \"file_id\", \n        fl.\"repo_name\" AS \"repo_name\", \n        fl.\"path\", \n        SPLIT(REPLACE(ct.\"content\", '\\n', ' \\n'), '\\n') AS \"lines\"\n    FROM \n        GITHUB_REPOS_DATE.GITHUB_REPOS.SAMPLE_FILES AS fl\n    JOIN \n        GITHUB_REPOS_DATE.GITHUB_REPOS.SAMPLE_CONTENTS AS ct \n        ON fl.\"id\" = ct.\"id\"\n) AS el,\nLATERAL FLATTEN(input => el.\"lines\") AS line \nWHERE\n    (\n        ENDSWITH(\"path_\", '.py') \n        AND \n        (\n            \"line_\" LIKE 'import %' \n            OR \n            \"line_\" LIKE 'from %'\n        )\n    )\n    OR\n    (\n        ENDSWITH(\"path_\", '.r') \n        AND \n        \"line_\" LIKE 'library%('\n    )\n\n),\nmodule_counts AS (\n    SELECT \n        em.\"language\",\n        f.value::STRING AS \"module\",\n        COUNT(*) AS \"occurrence_count\"\n    FROM \n        extracted_modules AS em,\n        LATERAL FLATTEN(input => em.\"modules\") AS f\n    WHERE \n        em.\"modules\" IS NOT NULL\n        AND f.value IS NOT NULL\n    GROUP BY \n        em.\"language\", \n        f.value\n),\npython AS (\n    SELECT \n        \"language\",\n        \"module\",\n        \"occurrence_count\"\n    FROM \n        module_counts\n    WHERE \n        \"language\" = 'python'\n),\nrlanguage AS (\n    SELECT \n        \"language\",\n        \"module\",\n        \"occurrence_count\"\n    FROM \n        module_counts AS mc_inner\n    WHERE \n        \"language\" = 'r'\n)\nSELECT \n    *\nFROM \n    python\nUNION ALL\nSELECT \n    *\nFROM \n    rlanguage\nORDER BY \n    \"language\", \n    \"occurrence_count\" DESC;",
        "external_path": "",
        "error_info": "Error occurred while executing act() on sample 5: Unable to load valid database schema for sample 5."
    },
    {
        "instance_id": "sf_bq248",
        "db_id": "GITHUB_REPOS",
        "question": "Among all repositories that do not use any programming language whose name (case-insensitively) includes the substring \"python,\" what is the proportion of files whose paths include \"readme.md\" and whose contents contain the phrase \"Copyright (c)\"?",
        "db_type": "snowflake",
        "db_size": 34,
        "query": "WITH requests AS (\n    SELECT \n        D.\"id\",\n        D.\"content\",\n        E.\"repo_name\",\n        E.\"path\"\n    FROM \n        (\n            SELECT \n                \"id\",\n                \"content\"\n            FROM \n                GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS\n            GROUP BY \n                \"id\", \"content\"\n        ) AS D\n    INNER JOIN \n        (\n            SELECT \n                C.\"id\",\n                C.\"repo_name\",\n                C.\"path\"\n            FROM \n                (\n                    SELECT \n                        \"id\",\n                        \"repo_name\",\n                        \"path\"\n                    FROM \n                        GITHUB_REPOS.GITHUB_REPOS.SAMPLE_FILES\n                    WHERE \n                        LOWER(\"path\") LIKE '%readme.md'\n                    GROUP BY \n                        \"path\", \"id\", \"repo_name\"\n                ) AS C\n            INNER JOIN \n                (\n                    SELECT \n                        \"repo_name\",\n                        language_struct.value:\"name\"::STRING AS \"language_name\"\n                    FROM \n                        GITHUB_REPOS.GITHUB_REPOS.LANGUAGES,\n                        LATERAL FLATTEN(input => \"language\") AS language_struct\n                    WHERE \n                        LOWER(language_struct.value:\"name\"::STRING) NOT LIKE '%python%'\n                    GROUP BY \n                        \"language_name\", \"repo_name\"\n                ) AS F\n            ON \n                C.\"repo_name\" = F.\"repo_name\"\n        ) AS E\n    ON \n        D.\"id\" = E.\"id\"\n)\nSELECT \n    (SELECT COUNT(*) FROM requests WHERE \"content\" LIKE '%Copyright (c)%') / COUNT(*) AS \"proportion\"\nFROM \n    requests;",
        "external_path": "",
        "error_info": "Error occurred while executing act() on sample 6: Unable to load valid database schema for sample 6."
    },
    {
        "instance_id": "sf_bq193",
        "db_id": "GITHUB_REPOS",
        "question": "Retrieve all non-empty, non-commented lines from `README.md` files in GitHub repositories, excluding lines that are comments (either starting with `#` for Markdown or `//` for code comments). For each line, calculate how often each unique line appears across all repositories and return a comma-separated list of the programming languages used in each repository containing that line, sorted alphabetically, with the results ordered by the frequency of occurrence in descending order.",
        "db_type": "snowflake",
        "db_size": 34,
        "query": "WITH content_extracted AS (\n    SELECT \n        \"D\".\"id\" AS \"id\",\n        \"repo_name\",\n        \"path\",\n        SPLIT(\"content\", '\\n') AS \"lines\",\n        \"language_name\"\n    FROM \n        (\n            SELECT \n                \"id\",\n                \"content\"\n            FROM \n                \"GITHUB_REPOS\".\"GITHUB_REPOS\".\"SAMPLE_CONTENTS\"\n        ) AS \"D\"\n    INNER JOIN \n        (\n            SELECT \n                \"id\",\n                \"C\".\"repo_name\" AS \"repo_name\",\n                \"path\",\n                \"language_name\"\n            FROM \n                (\n                    SELECT \n                        \"id\",\n                        \"repo_name\",\n                        \"path\"\n                    FROM \n                        \"GITHUB_REPOS\".\"GITHUB_REPOS\".\"SAMPLE_FILES\"\n                    WHERE \n                        LOWER(\"path\") LIKE '%readme.md'\n                ) AS \"C\"\n            INNER JOIN \n                (\n                    SELECT \n                        \"repo_name\",\n                        \"language_struct\".value:\"name\" AS \"language_name\"\n                    FROM \n                        (\n                            SELECT \n                                \"repo_name\", \n                                \"language\"\n                            FROM \n                                \"GITHUB_REPOS\".\"GITHUB_REPOS\".\"LANGUAGES\"\n                        )\n                    CROSS JOIN \n                        LATERAL FLATTEN(INPUT => \"language\") AS \"language_struct\"\n                ) AS \"F\"\n            ON \n                \"C\".\"repo_name\" = \"F\".\"repo_name\"\n        ) AS \"E\"\n    ON \n        \"E\".\"id\" = \"D\".\"id\"\n),\nnon_empty_lines AS (\n    SELECT \n        \"line\".value AS \"line_\",\n        \"language_name\"\n    FROM \n        content_extracted,\n        LATERAL FLATTEN(INPUT => \"lines\") AS \"line\"\n    WHERE \n        TRIM(\"line\".value) != ''\n        AND NOT STARTSWITH(TRIM(\"line\".value), '#')\n        AND NOT STARTSWITH(TRIM(\"line\".value), '//')\n),\naggregated_languages AS (\n    SELECT \n        \"line_\",\n        COUNT(*) AS \"frequency\",\n        ARRAY_AGG(\"language_name\") AS \"languages\"\n    FROM \n        non_empty_lines\n    GROUP BY \n        \"line_\"\n)\n\nSELECT \n    REGEXP_REPLACE(\"line_\", '^\"|\"$', '') AS \"line\",\n    \"frequency\",\n    ARRAY_TO_STRING(ARRAY_SORT(\"languages\"), ', ') AS \"languages_sorted\"\nFROM \n    aggregated_languages\nORDER BY \n    \"frequency\" DESC;",
        "external_path": "",
        "error_info": "Error occurred while executing act() on sample 7: Unable to load valid database schema for sample 7."
    },
    {
        "instance_id": "sf_bq249",
        "db_id": "GITHUB_REPOS",
        "question": "Please provide a report on the number of occurrences of specific line types across files from the GitHub repository. Categorize a line as 'trailing' if it ends with a blank character, as 'Space' if it starts with a space, and as 'Other' if it meets neither condition. The report should include the total number of occurrences for each category, considering all lines across all files.",
        "db_type": "snowflake",
        "db_size": 34,
        "query": "",
        "external_path": "",
        "error_info": "Error occurred while executing act() on sample 8: Unable to load valid database schema for sample 8."
    },
    {
        "instance_id": "sf_bq375",
        "db_id": "GITHUB_REPOS",
        "question": "Determine which file type among Python (.py), C (.c), Jupyter Notebook (.ipynb), Java (.java), and JavaScript (.js) in the GitHub codebase has the most files with a directory depth greater than 10, and provide the file count.",
        "db_type": "snowflake",
        "db_size": 34,
        "query": "",
        "external_path": "",
        "error_info": "Error occurred while executing act() on sample 9: Unable to load valid database schema for sample 9."
    },
    {
        "instance_id": "sf_bq255",
        "db_id": "GITHUB_REPOS",
        "question": "How many commit messages are there in repositories that use the 'Shell' programming language and 'apache-2.0' license, where the length of the commit message is more than 5 characters but less than 10,000 characters, and the messages do not start with the word 'merge', 'update' or 'test'?",
        "db_type": "snowflake",
        "db_size": 34,
        "query": "SELECT\n  COUNT(commits_table.\"message\") AS \"num_messages\"\nFROM (\n  SELECT\n    L.\"repo_name\",\n    language_struct.value:\"name\"::STRING AS \"language_name\"\n  FROM\n    GITHUB_REPOS.GITHUB_REPOS.LANGUAGES AS L,\n    LATERAL FLATTEN(input => L.\"language\") AS language_struct\n) AS lang_table\nJOIN \n  GITHUB_REPOS.GITHUB_REPOS.LICENSES AS license_table\nON \n  license_table.\"repo_name\" = lang_table.\"repo_name\"\nJOIN (\n  SELECT\n    *\n  FROM\n    GITHUB_REPOS.GITHUB_REPOS.SAMPLE_COMMITS\n) AS commits_table\nON \n  commits_table.\"repo_name\" = lang_table.\"repo_name\"\nWHERE\n  license_table.\"license\" LIKE 'apache-2.0'\n  AND lang_table.\"language_name\" LIKE 'Shell'\n  AND LENGTH(commits_table.\"message\") > 5\n  AND LENGTH(commits_table.\"message\") < 10000\n  AND LOWER(commits_table.\"message\") NOT LIKE 'update%'\n  AND LOWER(commits_table.\"message\") NOT LIKE 'test%'\n  AND LOWER(commits_table.\"message\") NOT LIKE 'merge%';",
        "external_path": "",
        "error_info": "Error occurred while executing act() on sample 10: Unable to load valid database schema for sample 10."
    },
    {
        "instance_id": "sf_bq194",
        "db_id": "GITHUB_REPOS",
        "question": "Among all Python (*.py), R (*.r, *.R, *.Rmd, *.rmd), and IPython notebook (*.ipynb) files in the GitHub sample dataset, which library or module is identified as the second most frequently imported or loaded based on the extracted import statements?",
        "db_type": "snowflake",
        "db_size": 34,
        "query": "",
        "external_path": "",
        "error_info": "Error occurred while executing act() on sample 11: Unable to load valid database schema for sample 11."
    },
    {
        "instance_id": "sf_bq377",
        "db_id": "GITHUB_REPOS",
        "question": "Extract and count the frequency of all package names listed in the require section of JSON-formatted content",
        "db_type": "snowflake",
        "db_size": 34,
        "query": "WITH json_files AS (\n  SELECT\n    c.\"id\",\n    TRY_PARSE_JSON(c.\"content\"):\"require\" AS \"dependencies\"\n  FROM\n    GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS c\n),\npackage_names AS (\n  SELECT\n    f.key AS \"package_name\"\n  FROM\n    json_files,\n    LATERAL FLATTEN(input => \"dependencies\") AS f\n)\nSELECT\n  \"package_name\",\n  COUNT(*) AS \"count\"\nFROM\n  package_names\nWHERE\n  \"package_name\" IS NOT NULL\nGROUP BY\n  \"package_name\"\nORDER BY\n  \"count\" DESC;",
        "external_path": "",
        "error_info": "Error occurred while executing act() on sample 12: Unable to load valid database schema for sample 12."
    },
    {
        "instance_id": "sf_bq359",
        "db_id": "GITHUB_REPOS",
        "question": "List the repository names and commit counts for the top two GitHub repositories with JavaScript as the primary language and the highest number of commits.",
        "db_type": "snowflake",
        "db_size": 34,
        "query": "WITH repositories AS (\n    SELECT\n        t2.\"repo_name\",\n        t2.\"language\"\n    FROM (\n        SELECT\n            t1.\"repo_name\",\n            t1.\"language\",\n            RANK() OVER (PARTITION BY t1.\"repo_name\" ORDER BY t1.\"language_bytes\" DESC) AS \"rank\"\n        FROM (\n            SELECT\n                l.\"repo_name\",\n                lang.value:\"name\"::STRING AS \"language\",\n                lang.value:\"bytes\"::NUMBER AS \"language_bytes\"\n            FROM\n                GITHUB_REPOS.GITHUB_REPOS.LANGUAGES AS l,\n                LATERAL FLATTEN(input => l.\"language\") AS lang\n        ) AS t1\n    ) AS t2\n    WHERE t2.\"rank\" = 1\n),\npython_repo AS (\n    SELECT\n        \"repo_name\",\n        \"language\"\n    FROM\n        repositories\n    WHERE\n        \"language\" = 'JavaScript'\n)\nSELECT \n    sc.\"repo_name\", \n    COUNT(sc.\"commit\") AS \"num_commits\"\nFROM \n    GITHUB_REPOS.GITHUB_REPOS.SAMPLE_COMMITS AS sc\nINNER JOIN \n    python_repo \nON \n    python_repo.\"repo_name\" = sc.\"repo_name\"\nGROUP BY \n    sc.\"repo_name\"\nORDER BY \n    \"num_commits\" DESC\nLIMIT 2;",
        "external_path": "",
        "error_info": "Error occurred while executing act() on sample 13: Unable to load valid database schema for sample 13."
    },
    {
        "instance_id": "sf_bq252",
        "db_id": "GITHUB_REPOS",
        "question": "Could you please find the name of the repository that contains the most copied non-binary Swift file in the dataset, ensuring each file is uniquely identified by its ID?",
        "db_type": "snowflake",
        "db_size": 34,
        "query": "WITH selected_repos AS (\n  SELECT\n    f.\"id\",\n    f.\"repo_name\" AS \"repo_name\",\n    f.\"path\" AS \"path\"\n  FROM\n    GITHUB_REPOS.GITHUB_REPOS.SAMPLE_FILES AS f\n),\ndeduped_files AS (\n  SELECT\n    f.\"id\",\n    MIN(f.\"repo_name\") AS \"repo_name\",\n    MIN(f.\"path\") AS \"path\"\n  FROM\n    selected_repos AS f\n  GROUP BY\n    f.\"id\"\n)\nSELECT\n  f.\"repo_name\"\nFROM\n  deduped_files AS f\n  JOIN GITHUB_REPOS.GITHUB_REPOS.SAMPLE_CONTENTS AS c \n  ON f.\"id\" = c.\"id\"\nWHERE\n  NOT c.\"binary\"\n  AND f.\"path\" LIKE '%.swift'\nORDER BY c.\"copies\" DESC\nLIMIT 1;",
        "external_path": "",
        "error_info": "Error occurred while executing act() on sample 14: Unable to load valid database schema for sample 14."
    },
    {
        "instance_id": "sf_bq251",
        "db_id": "PYPI",
        "question": "I want to know the GitHub project URLs for the top 3 most downloaded PyPI packages based on download count. First, extract PyPI package metadata including name, version, and project URLs. Filter these URLs to only include those that link to GitHub repositories. Use a regular expression to clean the GitHub URLs by removing unnecessary parts like 'issues', 'pull', 'blob', and 'tree' paths, keeping only the main repository URL. For packages with multiple versions, use only the most recent version based on upload time. Join this data with download metrics to determine the most downloaded packages. Return only the cleaned GitHub repository URLs (without quotation marks) for the top 3 packages by total download count, ensuring that only packages with valid GitHub URLs are included in the results.",
        "db_type": "snowflake",
        "db_size": 45,
        "query": "",
        "external_path": "",
        "error_info": "Error occurred while executing act() on sample 15: Unable to load valid database schema for sample 15."
    },
    {
        "instance_id": "bq130",
        "db_id": "covid19_nyt",
        "question": "Analyze daily new COVID-19 case counts from March to May 2020, identifying the top five states by daily increases. Please compile a ranking based on how often each state appears in these daily top fives. Then, examine the state that ranks fourth overall and identify its top five counties based on their frequency of appearing in the daily top five new case counts.",
        "db_type": "big_query",
        "db_size": 29,
        "query": "WITH StateCases AS (\n    SELECT\n        b.state_name,\n        b.date,\n        b.confirmed_cases - a.confirmed_cases AS daily_new_cases\n    FROM \n        (SELECT\n            state_name,\n            state_fips_code,\n            confirmed_cases,\n            DATE_ADD(date, INTERVAL 1 DAY) AS date_shift\n        FROM\n            `bigquery-public-data.covid19_nyt.us_states`\n        WHERE\n            date >= '2020-02-29' AND date <= '2020-05-30'\n        ) a\n    JOIN\n        `bigquery-public-data.covid19_nyt.us_states` b \n        ON a.state_fips_code = b.state_fips_code AND a.date_shift = b.date\n    WHERE\n        b.date >= '2020-03-01' AND b.date <= '2020-05-31'\n),\nRankedStatesPerDay AS (\n    SELECT\n        state_name,\n        date,\n        daily_new_cases,\n        RANK() OVER (PARTITION BY date ORDER BY daily_new_cases DESC) as rank\n    FROM\n        StateCases\n),\nTopStates AS (\n    SELECT\n        state_name,\n        COUNT(*) AS appearance_count\n    FROM\n        RankedStatesPerDay\n    WHERE\n        rank <= 5\n    GROUP BY\n        state_name\n    ORDER BY\n        appearance_count DESC\n),\nFourthState AS (\n    SELECT\n        state_name\n    FROM\n        TopStates\n    LIMIT 1\n    OFFSET 3\n),\nCountyCases AS (\n    SELECT\n        b.county,\n        b.date,\n        b.confirmed_cases - a.confirmed_cases AS daily_new_cases\n    FROM \n        (SELECT\n            county,\n            county_fips_code,\n            confirmed_cases,\n            DATE_ADD(date, INTERVAL 1 DAY) AS date_shift\n        FROM\n            `bigquery-public-data.covid19_nyt.us_counties`\n        WHERE\n            date >= '2020-02-29' AND date <= '2020-05-30'\n        ) a\n    JOIN\n        `bigquery-public-data.covid19_nyt.us_counties` b \n        ON a.county_fips_code = b.county_fips_code AND a.date_shift = b.date\n    WHERE\n        b.date >= '2020-03-01' AND b.date <= '2020-05-31'\n        AND b.state_name = (SELECT state_name FROM FourthState)\n),\nRankedCountiesPerDay AS (\n    SELECT\n        county,\n        date,\n        daily_new_cases,\n        RANK() OVER (PARTITION BY date ORDER BY daily_new_cases DESC) as rank\n    FROM\n        CountyCases\n),\nTopCounties AS (\n    SELECT\n        county,\n        COUNT(*) AS appearance_count\n    FROM\n        RankedCountiesPerDay\n    WHERE\n        rank <= 5\n    GROUP BY\n        county\n    ORDER BY\n        appearance_count DESC\n    LIMIT 5\n)\nSELECT\n    county\nFROM\n    TopCounties;",
        "external_path": "",
        "error_info": "Error occurred while executing act() on sample 16: Unable to load valid database schema for sample 16."
    },
    {
        "instance_id": "bq022",
        "db_id": "chicago",
        "question": "Calculate the minimum and maximum trip duration in minutes (rounded to the nearest whole number), total number of trips, and average fare for each of six equal quantile groups based on trip duration, considering only trips between 0 and 60 minutes.",
        "db_type": "big_query",
        "db_size": 45,
        "query": "SELECT\n  ROUND(MIN(trip_seconds) / 60, 0) AS min_minutes,\n  ROUND(MAX(trip_seconds) / 60, 0) AS max_minutes,\n  COUNT(*) AS total_trips,\n  AVG(fare) AS average_fare\nFROM (\n  SELECT\n    trip_seconds,\n    NTILE(6) OVER (ORDER BY trip_seconds) AS quantile,\n    fare\n  FROM\n    `bigquery-public-data.chicago_taxi_trips.taxi_trips`\n  WHERE\n    trip_seconds BETWEEN 0 AND 3600\n)\nGROUP BY\n  quantile\nORDER BY\n  min_minutes, max_minutes;",
        "external_path": "",
        "error_info": "Error occurred while executing act() on sample 17: Unable to load valid database schema for sample 17."
    },
    {
        "instance_id": "bq362",
        "db_id": "chicago",
        "question": "Which three companies had the largest increase in trip numbers between two consecutive months in 2018?",
        "db_type": "big_query",
        "db_size": 45,
        "query": "select company from\n            (select *,\n            row_number() over(partition by company order by month_o_month_calc desc) as rownum\n            from\n            (select *,\n            num_trips - lag(num_trips) over(partition by company order by month) as month_o_month_calc\n                from\n                (SELECT \n                company,\n                format_date(\"%Y-%m\", date_sub((cast(trip_start_timestamp as date)), interval 1 month)) as prev_month,\n                format_date(\"%Y-%m\", cast(trip_start_timestamp as date)) AS month,\n                count(1) AS num_trips\n                from `bigquery-public-data.chicago_taxi_trips.taxi_trips`\n                where extract(YEAR from trip_start_timestamp) = 2018\n                group by company, month, prev_month\n                order by company,month)\n            order by company, month_o_month_calc desc)\n            ) \n        where rownum = 1\n        order by month_o_month_calc desc, company \n        limit 3",
        "external_path": "",
        "error_info": "Error occurred while executing act() on sample 18: Unable to load valid database schema for sample 18."
    },
    {
        "instance_id": "bq363",
        "db_id": "chicago",
        "question": "Calculate the total number of trips and average fare (formatted to two decimal places) for ten equal-sized quantile groups. Each quantile group should contain approximately the same number of trips based on their rounded trip duration in minutes (between 1-50 minutes). Display each group's time range formatted as \"XXm to XXm\" (where the numbers are zero-padded to two digits), the total trips count, and the average fare. The time ranges should represent the minimum and maximum duration values within each quantile. Sort the results chronologically by time range. Use NTILE(10) to create the quantiles from the ordered trip durations.",
        "db_type": "big_query",
        "db_size": 45,
        "query": "SELECT\n  FORMAT('%02.0fm to %02.0fm', min_minutes, max_minutes) AS minutes_range,\n  SUM(trips) AS total_trips,\n  FORMAT('%3.2f', SUM(total_fare) / SUM(trips)) AS average_fare\nFROM (\n  SELECT\n    MIN(duration_in_minutes) OVER (quantiles) AS min_minutes,\n    MAX(duration_in_minutes) OVER (quantiles) AS max_minutes,\n    SUM(trips) AS trips,\n    SUM(total_fare) AS total_fare\n  FROM (\n    SELECT\n      ROUND(trip_seconds / 60) AS duration_in_minutes,\n      NTILE(10) OVER (ORDER BY trip_seconds / 60) AS quantile,\n      COUNT(1) AS trips,\n      SUM(fare) AS total_fare\n    FROM\n      `bigquery-public-data.chicago_taxi_trips.taxi_trips`\n    WHERE\n      ROUND(trip_seconds / 60) BETWEEN 1 AND 50\n    GROUP BY\n      trip_seconds,\n      duration_in_minutes )\n  GROUP BY\n    duration_in_minutes,\n    quantile\n  WINDOW quantiles AS (PARTITION BY quantile)\n  )\nGROUP BY\n  minutes_range\nORDER BY\n  Minutes_range",
        "external_path": "",
        "error_info": "Error occurred while executing act() on sample 19: Unable to load valid database schema for sample 19."
    },
    {
        "instance_id": "bq076",
        "db_id": "chicago",
        "question": "What is the highest number of motor vehicle theft incidents that occurred in any single month during 2016?",
        "db_type": "big_query",
        "db_size": 45,
        "query": "SELECT\n  incidents AS highest_monthly_thefts\nFROM (\n  SELECT\n    year,\n    EXTRACT(MONTH FROM date) AS month,\n    COUNT(1) AS incidents,\n    RANK() OVER (PARTITION BY year ORDER BY COUNT(1) DESC) AS ranking\n  FROM\n    `bigquery-public-data.chicago_crime.crime`\n  WHERE\n    primary_type = 'MOTOR VEHICLE THEFT'\n    AND year = 2016\n  GROUP BY\n    year,\n    month\n)\nWHERE\n  ranking = 1\nORDER BY\n  year DESC\nLIMIT 1;",
        "external_path": "",
        "error_info": "Error occurred while executing act() on sample 20: Unable to load valid database schema for sample 20."
    },
    {
        "instance_id": "bq077",
        "db_id": "chicago",
        "question": "For each year from 2010 to 2016, what is the highest number of motor thefts in one month?",
        "db_type": "big_query",
        "db_size": 45,
        "query": "SELECT\n  year,\n  incidents\nFROM (\n  SELECT\n    year,\n    EXTRACT(MONTH\n    FROM\n      date) AS month,\n    COUNT(1) AS incidents,\n    RANK() OVER (PARTITION BY year ORDER BY COUNT(1) DESC) AS ranking\n  FROM\n    `bigquery-public-data.chicago_crime.crime`\n  WHERE\n    primary_type = 'MOTOR VEHICLE THEFT'\n    AND year BETWEEN 2010 AND 2016\n  GROUP BY\n    year,\n    month )\nWHERE\n  ranking = 1\nORDER BY\n  year ASC",
        "external_path": "",
        "error_info": "Error occurred while executing act() on sample 21: Unable to load valid database schema for sample 21."
    },
    {
        "instance_id": "bq090",
        "db_id": "CYMBAL_INVESTMENTS",
        "question": "How much higher the average intrinsic value is for trades using the feeling-lucky strategy compared to those using the momentum strategy under long-side trades?",
        "db_type": "big_query",
        "db_size": 14,
        "query": "WITH MomentumTrades AS (\n  SELECT\n    StrikePrice - LastPx AS priceDifference\n  FROM\n    `bigquery-public-data.cymbal_investments.trade_capture_report`\n  WHERE\n    SUBSTR(TargetCompID, 0, 4) = 'MOMO'\n    AND (SELECT Side FROM UNNEST(Sides)) = 'LONG'\n),\n\nFeelingLuckyTrades AS (\n  SELECT\n    StrikePrice - LastPx AS priceDifference\n  FROM\n    `bigquery-public-data.cymbal_investments.trade_capture_report`\n  WHERE\n    SUBSTR(TargetCompID, 0, 4) = 'LUCK'\n    AND (SELECT Side FROM UNNEST(Sides)) = 'LONG'\n)\n\nSELECT\n  AVG(FeelingLuckyTrades.priceDifference) - AVG(MomentumTrades.priceDifference) AS averageDifference \nFROM\n  MomentumTrades,\n  FeelingLuckyTrades",
        "external_path": "",
        "error_info": "Error occurred while executing act() on sample 22: Unable to load valid database schema for sample 22."
    },
    {
        "instance_id": "bq442",
        "db_id": "CYMBAL_INVESTMENTS",
        "question": "Please collect the information of the top 6 trade report with the highest closing prices. Refer to the document for all the information I want.",
        "db_type": "big_query",
        "db_size": 14,
        "query": "SELECT\n  OrderID AS tradeID,\n  MaturityDate AS tradeTimestamp,\n  (\n    CASE SUBSTR(TargetCompID, 0, 4)\n      WHEN 'MOMO' THEN 'Momentum'\n      WHEN 'LUCK' THEN 'Feeling Lucky'\n      WHEN 'PRED' THEN 'Prediction'\n  END\n    ) AS algorithm,\n  Symbol AS symbol,\n  LastPx AS openPrice,\n  StrikePrice AS closePrice,\n  (\n  SELECT\n    Side\n  FROM\n    UNNEST(Sides)\n  ) AS tradeDirection,\n  (CASE (\n    SELECT\n      Side\n    FROM\n      UNNEST(Sides))\n      WHEN 'SHORT' THEN -1\n      WHEN 'LONG' THEN 1\n  END\n    ) AS tradeMultiplier\nFROM\n  `bigquery-public-data.cymbal_investments.trade_capture_report`cv\nORDER BY closePrice DESC\nLIMIT 6",
        "external_path": "..\\benchmarks\\spider2\\lite\\external\\Trade_Capture_Report_Data_List.md",
        "error_info": "Error occurred while executing act() on sample 23: Unable to load valid database schema for sample 23."
    },
    {
        "instance_id": "sf_bq104",
        "db_id": "GOOGLE_TRENDS",
        "question": "Based on the most recent refresh date, identify the top-ranked rising search term for the week that is exactly one year prior to the latest available week in the dataset.",
        "db_type": "snowflake",
        "db_size": 34,
        "query": "WITH LatestWeek AS (\n    SELECT\n        DATEADD(WEEK, -52, MAX(\"week\")) AS \"last_year_week\"\n    FROM\n        GOOGLE_TRENDS.GOOGLE_TRENDS.TOP_RISING_TERMS\n),\nLatestRefreshDate AS (\n    SELECT\n        MAX(\"refresh_date\") AS \"latest_refresh_date\"\n    FROM\n        GOOGLE_TRENDS.GOOGLE_TRENDS.TOP_RISING_TERMS\n),\nRankedTerms AS (\n    SELECT\n        \"term\",\n        \"week\",\n        CASE WHEN \"score\" IS NULL THEN NULL ELSE \"dma_name\" END AS \"dma_name\",\n        \"rank\",\n        \"score\",\n        ROW_NUMBER() OVER (\n            PARTITION BY \"term\", \"week\"\n            ORDER BY \"score\" DESC\n        ) AS rn\n    FROM\n        GOOGLE_TRENDS.GOOGLE_TRENDS.TOP_RISING_TERMS\n    WHERE\n        \"week\" = (SELECT \"last_year_week\" FROM LatestWeek)\n        AND \"refresh_date\" = (SELECT \"latest_refresh_date\" FROM LatestRefreshDate)\n)\n\nSELECT\n    \"term\"\nFROM\n    RankedTerms\nWHERE\n    rn = 1\nORDER BY\n    \"rank\"\nLIMIT 1;",
        "external_path": "",
        "error_info": "Error occurred while executing act() on sample 24: Unable to load valid database schema for sample 24."
    },
    {
        "instance_id": "sf_bq411",
        "db_id": "GOOGLE_TRENDS",
        "question": "Please retrieve the top three Google Trends search terms (ranks 1, 2, and 3) from top_terms for each weekday (Monday through Friday) between September 1, 2024, and September 14, 2024, grouped by the refresh_date column and ordered in descending order of refresh_date.",
        "db_type": "snowflake",
        "db_size": 34,
        "query": "",
        "external_path": "",
        "error_info": "Error occurred while executing act() on sample 25: Unable to load valid database schema for sample 25."
    },
    {
        "instance_id": "sf_bq458",
        "db_id": "WORD_VECTORS_US",
        "question": "Tokenize the body text of each article into words, excluding stop words, and obtain the corresponding word vectors for these words from the glove vector. For each word, weight its word vector by dividing each component by the 0.4th power of the word's frequency from the word frequencies. Then, for each article, aggregate these weighted word vectors by summing their components to form an article vector. Normalize each article vector to unit length by dividing by its magnitude. Finally, retrieve the ID, date, title, and the normalized article vector for each article.",
        "db_type": "snowflake",
        "db_size": 19,
        "query": "",
        "external_path": "..\\benchmarks\\spider2\\lite\\external\\tokenize_func.md",
        "error_info": "Error occurred while executing act() on sample 26: Unable to load valid database schema for sample 26."
    },
    {
        "instance_id": "sf_bq459",
        "db_id": "WORD_VECTORS_US",
        "question": "Please find the top 10 most relevant articles by only processing each articleâ€™s 'body' field, where each body is tokenized with no stopwords, each remaining token is turned into a GloVe-based word vector and weighted by dividing each dimension by the 0.4th power of its word frequency, then these weighted vectors are summed and normalized to get a unit vector for each article. Perform the same weighting and normalization on the query phrase 'Epigenetics and cerebral organoids: promising directions in autism spectrum disorders' and compute the cosine similarity between the query vector and each article vector. Finally, return the id, date, title, and the cosine similarity score for the top 10 articles with the highest similarity.",
        "db_type": "snowflake",
        "db_size": 19,
        "query": "",
        "external_path": "..\\benchmarks\\spider2\\lite\\external\\tokenize_func.md",
        "error_info": "Error occurred while executing act() on sample 27: Unable to load valid database schema for sample 27."
    },
    {
        "instance_id": "sf_bq460",
        "db_id": "WORD_VECTORS_US",
        "question": "Please process the articles from the 'nature' dataset by first tokenizing the body text into words and removing stopwords. For each remaining word, retrieve its word vector from the glove_vectors table and its frequency from the word_frequencies table, then divide each word vector by the 0.4th power of the word's frequency to weight it. Sum the weighted vectors to obtain an aggregate vector for each article, normalize this aggregate vector to unit length, and then compute the cosine similarity scores between these normalized vectors. Finally, return the IDs, dates, titles, and cosine similarity scores of the top 10 articles most similar to the article with the ID '8a78ef2d-d5f7-4d2d-9b47-5adb25cbd373'.",
        "db_type": "snowflake",
        "db_size": 19,
        "query": "",
        "external_path": "..\\benchmarks\\spider2\\lite\\external\\tokenize_func.md",
        "error_info": "Error occurred while executing act() on sample 28: Unable to load valid database schema for sample 28."
    },
    {
        "instance_id": "sf_bq219",
        "db_id": "IOWA_LIQUOR_SALES",
        "question": "In the Iowa Liquor Sales dataset, starting from January 1, 2022 through the last fully completed month, which two liquor categories, each contributing an average of at least 1% to the monthly sales volume over at least 24 months of available data, have the lowest Pearson correlation coefficient when comparing their monthly percentages of total liquor sales across those months, and what are their names?",
        "db_type": "snowflake",
        "db_size": 24,
        "query": "WITH\nMonthlyTotals AS\n(\n  SELECT\n    TO_CHAR(\"date\", 'YYYY-MM') AS \"month\",\n    SUM(\"volume_sold_gallons\") AS \"total_monthly_volume\"\n  FROM\n    IOWA_LIQUOR_SALES.IOWA_LIQUOR_SALES.\"SALES\"\n  WHERE\n    \"date\" >= '2022-01-01' \n    AND TO_CHAR(\"date\", 'YYYY-MM') < TO_CHAR(CURRENT_DATE(), 'YYYY-MM')\n  GROUP BY\n    TO_CHAR(\"date\", 'YYYY-MM')\n),\n\nMonthCategory AS\n(\n  SELECT\n    TO_CHAR(\"date\", 'YYYY-MM') AS \"month\",\n    \"category\",\n    \"category_name\",\n    SUM(\"volume_sold_gallons\") AS \"category_monthly_volume\",\n    CASE \n      WHEN \"total_monthly_volume\" != 0 THEN (SUM(\"volume_sold_gallons\") / \"total_monthly_volume\") * 100\n      ELSE NULL\n    END AS \"category_pct_of_month_volume\"\n  FROM\n    IOWA_LIQUOR_SALES.IOWA_LIQUOR_SALES.\"SALES\" AS Sales\n  LEFT JOIN\n    MonthlyTotals ON TO_CHAR(Sales.\"date\", 'YYYY-MM') = MonthlyTotals.\"month\"\n  WHERE\n    Sales.\"date\" >= '2022-01-01' \n    AND TO_CHAR(Sales.\"date\", 'YYYY-MM') < TO_CHAR(CURRENT_DATE(), 'YYYY-MM')\n  GROUP BY\n    TO_CHAR(Sales.\"date\", 'YYYY-MM'), \"category\", \"category_name\", \"total_monthly_volume\"\n),\n\nmiddle_info AS \n(\n  SELECT\n    Category1.\"category\" AS \"category1\",\n    Category1.\"category_name\" AS \"category_name1\",\n    Category2.\"category\" AS \"category2\",\n    Category2.\"category_name\" AS \"category_name2\",\n    COUNT(DISTINCT Category1.\"month\") AS \"num_months\",\n    CORR(Category1.\"category_pct_of_month_volume\", Category2.\"category_pct_of_month_volume\") AS \"category_corr_across_months\",\n    AVG(Category1.\"category_pct_of_month_volume\") AS \"category1_avg_pct_of_month_volume\",\n    AVG(Category2.\"category_pct_of_month_volume\") AS \"category2_avg_pct_of_month_volume\"\n  FROM\n    MonthCategory Category1\n  INNER JOIN\n    MonthCategory Category2 \n    ON Category1.\"month\" = Category2.\"month\"\n  GROUP BY\n    Category1.\"category\", Category1.\"category_name\", Category2.\"category\", Category2.\"category_name\"\n  HAVING\n    \"num_months\" >= 24\n    AND \"category1_avg_pct_of_month_volume\" >= 1\n    AND \"category2_avg_pct_of_month_volume\" >= 1\n)\n\nSELECT \n  \"category_name1\", \n  \"category_name2\"\nFROM \n  middle_info\nORDER BY \n  \"category_corr_across_months\"\nLIMIT 1;",
        "external_path": "",
        "error_info": "Error occurred while executing act() on sample 29: Unable to load valid database schema for sample 29."
    },
    {
        "instance_id": "bq199",
        "db_id": "iowa_liquor_sales",
        "question": "Identify the top 10 liquor categories in Iowa in 2021 by calculating, for each category, the average of the per-liter retail prices across all sales transactions in that category during 2021. For these top categories, provide their average per-liter retail prices calculated in the same manner for the years 2019, 2020, and 2021.",
        "db_type": "big_query",
        "db_size": 24,
        "query": "WITH price_2020 AS (\n  SELECT \n    category_name AS category, \n    AVG(state_bottle_retail / (bottle_volume_ml / 1000)) AS avg_price_liter_2020\n  FROM \n    `bigquery-public-data.iowa_liquor_sales.sales`\n  WHERE \n    bottle_volume_ml > 0 \n    AND EXTRACT(YEAR FROM date) = 2020\n  GROUP BY \n    category\n),\nprice_2019 AS (\n  SELECT \n    category_name AS category, \n    AVG(state_bottle_retail / (bottle_volume_ml / 1000)) AS avg_price_liter_2019\n  FROM \n    `bigquery-public-data.iowa_liquor_sales.sales`\n  WHERE \n    bottle_volume_ml > 0 \n    AND EXTRACT(YEAR FROM date) = 2019\n  GROUP BY \n    category\n),\nprice_2021 AS (\n  SELECT \n    category_name AS category, \n    AVG(state_bottle_retail / (bottle_volume_ml / 1000)) AS avg_price_liter_2021\n  FROM \n    `bigquery-public-data.iowa_liquor_sales.sales`\n  WHERE \n    bottle_volume_ml > 0 \n    AND EXTRACT(YEAR FROM date) = 2021\n  GROUP BY \n    category\n)\nSELECT \n  price_2021.category, \n  price_2019.avg_price_liter_2019, \n  price_2020.avg_price_liter_2020, \n  price_2021.avg_price_liter_2021\nFROM \n  price_2021\nLEFT JOIN \n  price_2019 ON price_2021.category = price_2019.category\nLEFT JOIN \n  price_2020 ON price_2021.category = price_2020.category\nORDER BY \n  price_2021.avg_price_liter_2021 DESC\nLIMIT \n  10;",
        "external_path": "",
        "error_info": "Error occurred while executing act() on sample 30: Unable to load valid database schema for sample 30."
    },
    {
        "instance_id": "bq218",
        "db_id": "iowa_liquor_sales",
        "question": "What are the top 5 items with the highest year-over-year growth percentage in total sales revenue for the year 2023?",
        "db_type": "big_query",
        "db_size": 24,
        "query": "WITH AnnualSales AS (\n  SELECT\n    item_description,\n    EXTRACT(YEAR FROM date) AS year,\n    SUM(sale_dollars) AS total_sales_revenue,\n    COUNT(DISTINCT invoice_and_item_number) AS unique_purchases\n  FROM\n    `bigquery-public-data.iowa_liquor_sales.sales`\n  WHERE\n    EXTRACT(YEAR FROM date) IN (2022, 2023)\n    AND item_description IS NOT NULL\n    AND sale_dollars IS NOT NULL\n  GROUP BY\n    item_description, year\n),\nYoYGrowth AS (\n  SELECT\n    curr.item_description,\n    curr.year,\n    curr.total_sales_revenue,\n    curr.unique_purchases,\n    LAG(curr.total_sales_revenue) OVER(PARTITION BY curr.item_description ORDER BY curr.year) AS prev_year_sales_revenue,\n    (curr.total_sales_revenue - LAG(curr.total_sales_revenue) OVER(PARTITION BY curr.item_description ORDER BY curr.year)) / LAG(curr.total_sales_revenue) OVER(PARTITION BY curr.item_description ORDER BY curr.year) * 100 AS yoy_growth_percentage\n  FROM\n    AnnualSales curr\n),\ntotal_info AS (\nSELECT\n  item_description,\n  year,\n  total_sales_revenue,\n  unique_purchases,\n  prev_year_sales_revenue,\n  yoy_growth_percentage\nFROM\n  YoYGrowth\nWHERE\n  year = 2023\n  AND prev_year_sales_revenue IS NOT NULL -- Exclude rows where there's no previous year data to calculate YoY growth\nORDER BY\n  year, total_sales_revenue \nDESC\n)\n\nSELECT item_description\nFROM total_info\norder by yoy_growth_percentage\nDESC\nLIMIT 5",
        "external_path": "",
        "error_info": "Error occurred while executing act() on sample 31: Unable to load valid database schema for sample 31."
    },
    {
        "instance_id": "bq049",
        "db_id": "iowa_liquor_sales_plus",
        "question": "Please show the monthly per capita Bourbon Whiskey sales during 2022 in Dubuque County for the zip code that ranks third in total Bourbon Whiskey sales, using only the population aged 21 and older.",
        "db_type": "big_query",
        "db_size": 36,
        "query": "WITH DUBUQUE_LIQUOR_CTE AS (\nSELECT\n  CASE\n      WHEN UPPER(category_name) LIKE 'BUTTERSCOTCH SCHNAPPS' THEN 'All Other' --Edge case is not a scotch\n      WHEN UPPER(category_name) LIKE '%WHISKIES' \n            AND UPPER(category_name) NOT LIKE '%RYE%'\n            AND UPPER(category_name) NOT LIKE '%BOURBON%'\n            AND UPPER(category_name) NOT LIKE '%SCOTCH%'     THEN 'Other Whiskey'\n      WHEN UPPER(category_name) LIKE '%RYE%'                 THEN 'Rye Whiskey'\n      WHEN UPPER(category_name) LIKE '%BOURBON%'             THEN 'Bourbon Whiskey'\n      WHEN UPPER(category_name) LIKE '%SCOTCH%'              THEN 'Scotch Whiskey'\n      ELSE 'All Other'\n  END                              AS category_group,\n  EXTRACT(MONTH FROM date)         AS month,    -- At the time of this query, there is only data until month 6.\n  LEFT(CAST(zip_code AS string),5) AS zip_code, -- Casting to string necessary because zip_code has a mix of int & str types.\n  ROUND(SUM(sale_dollars), 2)      AS sale_dollars_sum,\n\nFROM \n  bigquery-public-data.iowa_liquor_sales.sales\n\nWHERE\n  UPPER(county)               = 'DUBUQUE'\n  AND EXTRACT(YEAR FROM date) = 2022\n\nGROUP BY\n  category_group,\n  month,\n  zip_code\n  \nORDER BY \n  category_group,\n  month,\n  zip_code\n),\n\nDUBUQUE_POPULATION_CTE AS (\nSELECT\n  zipcode,\n  SUM(population) AS population_sum\nFROM bigquery-public-data.census_bureau_usa.population_by_zip_2010\nWHERE \n  minimum_age >= 21\nGROUP BY \n  zipcode\n),\nMONTH_INFO AS (\nSELECT \n  l.month,\n  l.zip_code,\n  l.sale_dollars_sum,\n  ROUND(sale_dollars_sum/p.population_sum, 2) AS dollars_per_capita\nFROM \n  DUBUQUE_LIQUOR_CTE AS l\n  LEFT JOIN \n  DUBUQUE_POPULATION_CTE AS p\n  ON l.zip_code = p.zipcode\nWHERE\n  category_group = 'Bourbon Whiskey'\nGROUP BY \n  category_group,\n  zip_code,\n  month,\n  sale_dollars_sum,\n  zipcode,\n  population_sum\nORDER BY\n  zip_code,\n  month\n),\nzip_code_sales AS (\n    SELECT\n        zip_code,\n        SUM(sale_dollars_sum) AS total_sale_dollars_sum\n    FROM MONTH_INFO\n    GROUP BY zip_code\n),\nranked_zip_codes AS (\n    SELECT\n        zip_code,\n        total_sale_dollars_sum,\n        ROW_NUMBER() OVER (ORDER BY total_sale_dollars_sum DESC) AS rank\n    FROM zip_code_sales\n)\nSELECT\n    t.month,\n    t.zip_code,\n    t.dollars_per_capita\nFROM MONTH_INFO t\nJOIN ranked_zip_codes r\nON t.zip_code = r.zip_code\nWHERE r.rank = 3\nORDER BY t.month;",
        "external_path": "",
        "error_info": "Error occurred while executing act() on sample 32: Unable to load valid database schema for sample 32."
    },
    {
        "instance_id": "bq286",
        "db_id": "usa_names",
        "question": "Can you tell me the name of the most popular female baby in Wyoming for the year 2021, based on the proportion of female babies given that name compared to the total number of female babies given the same name across all states?",
        "db_type": "big_query",
        "db_size": 10,
        "query": "SELECT\n  a.name AS name\nFROM\n  `bigquery-public-data.usa_names.usa_1910_current` a\nJOIN (\n  SELECT\n    name,\n    gender,\n    year,\n    SUM(number) AS total_number\n  FROM\n    `bigquery-public-data.usa_names.usa_1910_current`\n  GROUP BY\n    name,\n    gender,\n    year) b\nON\n  a.name = b.name\n  AND a.gender = b.gender\n  AND a.year = b.year\nWHERE \n    a.gender = 'F' AND\n    a.state = 'WY' AND\n    a.year = 2021\nORDER BY (a.number / b.total_number) DESC\nLIMIT 1",
        "external_path": "",
        "error_info": "Error occurred while executing act() on sample 33: Unable to load valid database schema for sample 33."
    },
    {
        "instance_id": "bq284",
        "db_id": "bbc",
        "question": "Can you provide a breakdown of the total number of articles into different categories and the percentage of those articles that mention \"education\" within each category from the BBC News?",
        "db_type": "big_query",
        "db_size": 4,
        "query": "SELECT \n  category,\n  COUNT(*) AS number_total_by_category,  \n  CASE \n    WHEN category = 'tech' THEN \n          (SELECT count(*)\n                FROM `bigquery-public-data.bbc_news.fulltext`\n                WHERE (LOWER(body) LIKE '%education%') AND category = 'tech') * 100 /\n                (SELECT count(*)\n                FROM `bigquery-public-data.bbc_news.fulltext`\n                WHERE category = 'tech')\n    WHEN category = 'sport' THEN \n          (SELECT count(*)\n                FROM `bigquery-public-data.bbc_news.fulltext`\n                WHERE (LOWER(body) LIKE '%education%') AND category = 'sport') * 100 /\n                (SELECT count(*)\n                FROM `bigquery-public-data.bbc_news.fulltext`\n                WHERE category = 'sport')\n    WHEN category = 'business' THEN \n          (SELECT count(*)\n                FROM `bigquery-public-data.bbc_news.fulltext`\n                WHERE (LOWER(body) LIKE '%education%') AND category = 'business') * 100 /\n                (SELECT count(*)\n                FROM `bigquery-public-data.bbc_news.fulltext`\n                WHERE category = 'business')\n    WHEN category = 'politics' THEN \n          (SELECT count(*)\n                FROM `bigquery-public-data.bbc_news.fulltext`\n                WHERE (LOWER(body) LIKE '%education%') AND category = 'politics') * 100 /\n                (SELECT count(*)\n                FROM `bigquery-public-data.bbc_news.fulltext`\n                WHERE category = 'politics')\n    WHEN category = 'entertainment' THEN \n          (SELECT count(*)\n                FROM `bigquery-public-data.bbc_news.fulltext`\n                WHERE (LOWER(body) LIKE '%education%') AND category = 'entertainment') * 100 /\n                (SELECT count(*)\n                FROM `bigquery-public-data.bbc_news.fulltext`\n                WHERE category = 'entertainment')\n  END AS percent_education\nFROM `bigquery-public-data.bbc_news.fulltext`\nGROUP BY\n  category;",
        "external_path": "",
        "error_info": "Error occurred while executing act() on sample 34: Unable to load valid database schema for sample 34."
    },
    {
        "instance_id": "sf_bq412",
        "db_id": "GOOGLE_ADS",
        "question": "Please retrieve the page URLs, first shown time, last shown time, removal reason, violation category, and the lower and upper bounds of times shown for the five most recently removed ads in the Croatia region (region code 'HR'), where the times shown availability date is null, the times shown lower bound exceeds 10,000, the times shown upper bound is below 25,000, and the ads used at least one non-unused audience selection approach among demographics, geographic location, contextual signals, customer lists, or topics of interest, ordering the resulting ads by their last shown time in descending order.",
        "db_type": "snowflake",
        "db_size": 16,
        "query": "SELECT\n    \"creative_page_url\",\n    TO_TIMESTAMP(GET(\"region_stat\".value, 'first_shown')) AS \"first_shown\",\n    TO_TIMESTAMP(GET(\"region_stat\".value, 'last_shown')) AS \"last_shown\",\n    REPLACE(REPLACE(\"disapproval\"[0].\"removal_reason\", '\"\"', '\"'), '\"', '') AS \"removal_reason\", \n    REPLACE(REPLACE(\"disapproval\"[0].\"violation_category\", '\"\"', '\"'), '\"', '') AS \"violation_category\",\n    GET(\"region_stat\".value, 'times_shown_lower_bound') AS \"times_shown_lower\",\n    GET(\"region_stat\".value, 'times_shown_upper_bound') AS \"times_shown_upper\"\nFROM\n    \"GOOGLE_ADS\".\"GOOGLE_ADS_TRANSPARENCY_CENTER\".\"REMOVED_CREATIVE_STATS\",\n    LATERAL FLATTEN(input => \"region_stats\") AS \"region_stat\"\nWHERE\n    GET(\"region_stat\".value, 'region_code') = 'HR' \n    AND GET(\"region_stat\".value, 'times_shown_availability_date') IS NULL \n    AND GET(\"region_stat\".value, 'times_shown_lower_bound') > 10000 \n    AND GET(\"region_stat\".value, 'times_shown_upper_bound') < 25000\n    AND (\n        GET(\"audience_selection_approach_info\", 'demographic_info') != 'CRITERIA_UNUSED' \n        OR GET(\"audience_selection_approach_info\", 'geo_location') != 'CRITERIA_UNUSED' \n        OR GET(\"audience_selection_approach_info\", 'contextual_signals') != 'CRITERIA_UNUSED' \n        OR GET(\"audience_selection_approach_info\", 'customer_lists') != 'CRITERIA_UNUSED' \n        OR GET(\"audience_selection_approach_info\", 'topics_of_interest') != 'CRITERIA_UNUSED'\n    )\nORDER BY\n    \"last_shown\" DESC\nLIMIT 5;",
        "external_path": "",
        "error_info": "Error occurred while executing act() on sample 35: Unable to load valid database schema for sample 35."
    },
    {
        "instance_id": "sf_bq423",
        "db_id": "GOOGLE_ADS",
        "question": "Between January 1, 2023, and January 1, 2024, which image-type advertisement on the topic of Health, published by a verified advertiser located in Cyprus, was shown in Croatia, has times_shown_availability_date as NULL (meaning the times shown data is available), utilized demographic information, geo-location targeting, contextual signals, customer lists, and topics of interest without any of these selection methods being unused, and additionally had its first shown date strictly after January 1, 2023, and last shown date strictly before January 1, 2024? Among such ads, provide the page URL of the one with the highest upper bound of times shown.",
        "db_type": "snowflake",
        "db_size": 16,
        "query": "",
        "external_path": "",
        "error_info": "Error occurred while executing act() on sample 36: Unable to load valid database schema for sample 36."
    },
    {
        "instance_id": "bq227",
        "db_id": "london",
        "question": "Could you provide the annual percentage shares, rounded to two decimal places, of the top 5 minor crime categories from 2008 in London's total crimes, with each year displayed in one row?",
        "db_type": "big_query",
        "db_size": 39,
        "query": "WITH top5_categories AS (\n  SELECT minor_category\n  FROM `bigquery-public-data.london_crime.crime_by_lsoa`\n  WHERE year = 2008\n  GROUP BY minor_category\n  ORDER BY SUM(value) DESC\n  LIMIT 5\n),\n\ntotal_crimes_per_year AS (\n  SELECT \n    year, \n    SUM(value) AS total_crimes_year\n  FROM `bigquery-public-data.london_crime.crime_by_lsoa`\n  GROUP BY year\n),\n\ntop5_crimes_per_year AS (\n  SELECT\n    year,\n    minor_category,\n    SUM(value) AS total_crimes_category_year\n  FROM `bigquery-public-data.london_crime.crime_by_lsoa`\n  WHERE minor_category IN (SELECT minor_category FROM top5_categories)\n  GROUP BY year, minor_category\n)\n\nSELECT\n  t.year,\n  ROUND(SUM(CASE WHEN t.minor_category = (SELECT minor_category FROM top5_categories LIMIT 1 OFFSET 0) THEN t.total_crimes_category_year ELSE 0 END) / y.total_crimes_year * 100, 2) AS `Category 1`,\n  ROUND(SUM(CASE WHEN t.minor_category = (SELECT minor_category FROM top5_categories LIMIT 1 OFFSET 1) THEN t.total_crimes_category_year ELSE 0 END) / y.total_crimes_year * 100, 2) AS `Category 2`,\n  ROUND(SUM(CASE WHEN t.minor_category = (SELECT minor_category FROM top5_categories LIMIT 1 OFFSET 2) THEN t.total_crimes_category_year ELSE 0 END) / y.total_crimes_year * 100, 2) AS `Category 3`,\n  ROUND(SUM(CASE WHEN t.minor_category = (SELECT minor_category FROM top5_categories LIMIT 1 OFFSET 3) THEN t.total_crimes_category_year ELSE 0 END) / y.total_crimes_year * 100, 2) AS `Category 4`,\n  ROUND(SUM(CASE WHEN t.minor_category = (SELECT minor_category FROM top5_categories LIMIT 1 OFFSET 4) THEN t.total_crimes_category_year ELSE 0 END) / y.total_crimes_year * 100, 2) AS `Category 5`\nFROM\n  top5_crimes_per_year t\nJOIN\n  total_crimes_per_year y ON t.year = y.year\nGROUP BY\n  t.year, y.total_crimes_year\nORDER BY\n  t.year;",
        "external_path": "",
        "error_info": "Error occurred while executing act() on sample 37: Unable to load valid database schema for sample 37."
    },
    {
        "instance_id": "bq232",
        "db_id": "london",
        "question": "Could you provide the total number of 'Other Theft' incidents within the 'Theft and Handling' category for each year in the Westminster borough?",
        "db_type": "big_query",
        "db_size": 39,
        "query": "WITH borough_data AS (\n    SELECT \n        year, \n        month, \n        borough, \n        major_category, \n        minor_category, \n        SUM(value) AS total,\n    CASE \n        WHEN \n            major_category = 'Theft and Handling' \n        THEN \n            'Theft and Handling'\n        ELSE \n            'Other' \n    END AS major_division,\n    CASE \n        WHEN \n            minor_category = 'Other Theft' THEN minor_category\n        ELSE \n            'Other'\n    END AS minor_division,\n    FROM \n        bigquery-public-data.london_crime.crime_by_lsoa\n    GROUP BY 1,2,3,4,5\n    ORDER BY 1,2\n)\n\nSELECT year, SUM(total) AS year_total\nFROM borough_data\nWHERE \n    borough = 'Westminster'\nAND\n    major_division != 'Other'\nAND \n    minor_division != 'Other'\nGROUP BY year, major_division, minor_division\nORDER BY year;",
        "external_path": "",
        "error_info": "Error occurred while executing act() on sample 38: Unable to load valid database schema for sample 38."
    },
    {
        "instance_id": "bq228",
        "db_id": "london",
        "question": "Please provide a list of the top three major crime categories in the borough of Barking and Dagenham, along with the number of incidents in each category.",
        "db_type": "big_query",
        "db_size": 39,
        "query": "WITH ranked_crimes AS (\n    SELECT\n        borough,\n        major_category,\n        RANK() OVER(PARTITION BY borough ORDER BY SUM(value) DESC) AS rank_per_borough,\n        SUM(value) AS no_of_incidents\n    FROM\n        `bigquery-public-data.london_crime.crime_by_lsoa`\n    GROUP BY\n        borough,\n        major_category\n)\n\nSELECT\n    borough,\n    major_category,\n    rank_per_borough,\n    no_of_incidents\nFROM\n    ranked_crimes\nWHERE\n    rank_per_borough <= 3\nAND \n    borough = 'Barking and Dagenham'\nORDER BY\n    borough,\n    rank_per_borough;",
        "external_path": "",
        "error_info": "Error occurred while executing act() on sample 39: Unable to load valid database schema for sample 39."
    },
    {
        "instance_id": "bq229",
        "db_id": "open_images",
        "question": "Using the bigquery-public-data.open_images dataset, can you provide a count of how many distinct image URLs are categorized as 'cat' (where the image has label '/m/01yrx' with confidence=1) and how many distinct image URLs are categorized as 'other' (meaning they have no cat label '/m/01yrx' at all)?",
        "db_type": "big_query",
        "db_size": 30,
        "query": "",
        "external_path": "",
        "error_info": "Error occurred while executing act() on sample 40: Unable to load valid database schema for sample 40."
    },
    {
        "instance_id": "bq393",
        "db_id": "hacker_news",
        "question": "I want to identify users who had activity followed by inactivity. Specifically, find the user ID and their corresponding month number (counting from their first activity month) for the user with the highest month number who became inactive (no activity recorded) after their last recorded activity month. For this analysis, only consider data up until September 10, 2024, and ensure the month number represents the count of months since the user's first activity. The user should have at least one month where they were expected to be active (within their activity span) but actually had no records.",
        "db_type": "big_query",
        "db_size": 14,
        "query": "",
        "external_path": "",
        "error_info": "Error occurred while executing act() on sample 41: Unable to load valid database schema for sample 41."
    },
    {
        "instance_id": "local009",
        "db_id": "Airlines",
        "question": "What is the distance of the longest route where Abakan is either the departure or destination city (in kilometers)?",
        "db_type": "sqlite",
        "db_size": 35,
        "query": "",
        "external_path": "..\\benchmarks\\spider2\\lite\\external\\haversine_formula.md",
        "error_info": "Error occurred while executing act() on sample 42: Unable to load valid database schema for sample 42."
    },
    {
        "instance_id": "local010",
        "db_id": "Airlines",
        "question": "Distribute all the unique city pairs into the distance ranges 0, 1000, 2000, 3000, 4000, 5000, and 6000+, based on their average distance of all routes between them. Then how many pairs are there in the distance range with the fewest unique city paires?",
        "db_type": "sqlite",
        "db_size": 35,
        "query": "",
        "external_path": "..\\benchmarks\\spider2\\lite\\external\\haversine_formula.md",
        "error_info": "Error occurred while executing act() on sample 43: Unable to load valid database schema for sample 43."
    },
    {
        "instance_id": "local019",
        "db_id": "WWE",
        "question": "For the NXT title that had the shortest match (excluding titles with \"title change\"), what were the names of the two wrestlers involved?",
        "db_type": "sqlite",
        "db_size": 35,
        "query": "WITH MatchDetails AS (\n    SELECT\n        b.name AS titles,\n        m.duration AS match_duration,\n        w1.name || ' vs ' || w2.name AS matches,\n        m.win_type AS win_type,\n        l.name AS location,\n        e.name AS event,\n        ROW_NUMBER() OVER (PARTITION BY b.name ORDER BY m.duration ASC) AS rank\n    FROM \n        Belts b\n    INNER JOIN Matches m ON m.title_id = b.id\n    INNER JOIN Wrestlers w1 ON w1.id = m.winner_id\n    INNER JOIN Wrestlers w2 ON w2.id = m.loser_id\n    INNER JOIN Cards c ON c.id = m.card_id\n    INNER JOIN Locations l ON l.id = c.location_id\n    INNER JOIN Events e ON e.id = c.event_id\n    INNER JOIN Promotions p ON p.id = c.promotion_id\n    WHERE\n        p.name = 'NXT'\n        AND m.duration <> ''\n        AND b.name <> ''\n        AND b.name NOT IN (\n            SELECT name \n            FROM Belts \n            WHERE name LIKE '%title change%'\n        )\n),\nRank1 AS (\nSELECT \n    titles,\n    match_duration,\n    matches,\n    win_type,\n    location,\n    event\nFROM \n    MatchDetails\nWHERE \n    rank = 1\n)\nSELECT\n    SUBSTR(matches, 1, INSTR(matches, ' vs ') - 1) AS wrestler1,\n    SUBSTR(matches, INSTR(matches, ' vs ') + 4) AS wrestler2\nFROM\nRank1\nORDER BY match_duration \nLIMIT 1",
        "external_path": "",
        "error_info": "Error occurred while executing act() on sample 44: Unable to load valid database schema for sample 44."
    },
    {
        "instance_id": "local152",
        "db_id": "imdb_movies",
        "question": "Can you provide the top 9 directors by movie count, including their ID, name, number of movies, average inter-movie duration (rounded to the nearest integer), average rating (rounded to 2 decimals), total votes, minimum and maximum ratings, and total movie duration? Sort the output first by movie count in descending order and then by total movie duration in descending order.",
        "db_type": "sqlite",
        "db_size": 38,
        "query": "",
        "external_path": "",
        "error_info": "Error occurred while executing act() on sample 45: Unable to load valid database schema for sample 45."
    },
    {
        "instance_id": "local230",
        "db_id": "imdb_movies",
        "question": "Determine the top three genres with the most movies rated above 8, and then identify the top four directors who have directed the most films rated above 8 within those genres. List these directors and their respective movie counts.",
        "db_type": "sqlite",
        "db_size": 38,
        "query": "",
        "external_path": "",
        "error_info": "Error occurred while executing act() on sample 46: Unable to load valid database schema for sample 46."
    }
]